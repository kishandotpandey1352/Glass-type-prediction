{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About Dataset: \n",
    "This is about prediction of a Glass type based on the on its constituents/content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data from axcel form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel(\"glass.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=data.iloc[:,1:10], data[\"Prod_Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 214 entries, 0 to 213\n",
      "Data columns (total 9 columns):\n",
      "RI    214 non-null float64\n",
      "Na    214 non-null float64\n",
      "Mg    214 non-null float64\n",
      "Al    214 non-null float64\n",
      "Si    214 non-null float64\n",
      "K     214 non-null float64\n",
      "Ca    214 non-null float64\n",
      "Ba    214 non-null float64\n",
      "Fe    214 non-null float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 15.2 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(214, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.info()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "print(y.unique())#unique values from the target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Considering the data is cleaned and not performing the necessary EDA and Feature selection and extraction. This is just to learn how to use Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =train_test_split(X,y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating SVM with Radial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kishan\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=42,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model_rbf =SVC(kernel='rbf', random_state=42)\n",
    "model_rbf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6481481481481481\n",
      "[[14  0  0  0  0  0]\n",
      " [10 10  0  1  0  0]\n",
      " [ 4  0  0  0  0  0]\n",
      " [ 0  1  0  3  0  0]\n",
      " [ 0  2  0  0  1  0]\n",
      " [ 0  0  0  0  1  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      1.00      0.67        14\n",
      "           2       0.77      0.48      0.59        21\n",
      "           3       0.00      0.00      0.00         4\n",
      "           5       0.75      0.75      0.75         4\n",
      "           6       0.50      0.33      0.40         3\n",
      "           7       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.65        54\n",
      "   macro avg       0.59      0.57      0.56        54\n",
      "weighted avg       0.66      0.65      0.62        54\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kishan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "y_pred=model_rbf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, model_rbf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The radial SVM provides much less accuracy ie, 65%. Lets apply some other classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (n)  in a multiclass , we see the F1 score, Precision, and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating SVM Linear Kernel `m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=42,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lin=SVC(kernel='linear', random_state=42)\n",
    "model_lin.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6481481481481481\n",
      "[[13  1  0  0  0  0]\n",
      " [ 8 11  0  0  1  1]\n",
      " [ 3  1  0  0  0  0]\n",
      " [ 0  1  0  3  0  0]\n",
      " [ 0  1  0  1  1  0]\n",
      " [ 0  1  0  0  0  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.93      0.68        14\n",
      "           2       0.69      0.52      0.59        21\n",
      "           3       0.00      0.00      0.00         4\n",
      "           5       0.75      0.75      0.75         4\n",
      "           6       0.50      0.33      0.40         3\n",
      "           7       0.88      0.88      0.88         8\n",
      "\n",
      "    accuracy                           0.65        54\n",
      "   macro avg       0.56      0.57      0.55        54\n",
      "weighted avg       0.62      0.65      0.62        54\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kishan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "y_pred=model_lin.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, model_lin.predict(X_test)))# the point lying within the hyperplane from 0 to distance w/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating SVM with poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.8, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=2, gamma=0.1, kernel='poly',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rbf =SVC(kernel='poly', gamma =0.1, C=0.8, degree = 2)\n",
    "model_rbf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7592592592592593\n",
      "[[13  1  0  0  0  0]\n",
      " [ 4 15  0  0  2  0]\n",
      " [ 3  1  0  0  0  0]\n",
      " [ 0  0  0  4  0  0]\n",
      " [ 0  0  0  1  2  0]\n",
      " [ 1  0  0  0  0  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.93      0.74        14\n",
      "           2       0.88      0.71      0.79        21\n",
      "           3       0.00      0.00      0.00         4\n",
      "           5       0.80      1.00      0.89         4\n",
      "           6       0.50      0.67      0.57         3\n",
      "           7       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.76        54\n",
      "   macro avg       0.63      0.70      0.65        54\n",
      "weighted avg       0.74      0.76      0.74        54\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kishan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "y_pred=model_rbf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, model_rbf.predict(X_test)))# the point lying within the hyperplane from 0 to distance w/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The poly-SVM provides a little better  accuracy ie, 76%. Lets apply some other classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier#dont increase no. of trees if accuracy does not increase\n",
    "rf1=RandomForestClassifier(n_estimators=50, criterion='gini', max_depth=4, random_state=42)\n",
    "rf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7407407407407407\n",
      "[[14  0  0  0  0  0]\n",
      " [ 6 11  0  2  1  1]\n",
      " [ 3  0  1  0  0  0]\n",
      " [ 0  1  0  3  0  0]\n",
      " [ 0  0  0  0  3  0]\n",
      " [ 0  0  0  0  0  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      1.00      0.76        14\n",
      "           2       0.92      0.52      0.67        21\n",
      "           3       1.00      0.25      0.40         4\n",
      "           5       0.60      0.75      0.67         4\n",
      "           6       0.75      1.00      0.86         3\n",
      "           7       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.74        54\n",
      "   macro avg       0.79      0.75      0.71        54\n",
      "weighted avg       0.81      0.74      0.72        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "y_pred=rf1.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, rf1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=42, splitter='best')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt=DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7222222222222222\n",
      "[[13  1  0  0  0  0]\n",
      " [ 5 14  0  2  0  0]\n",
      " [ 3  1  0  0  0  0]\n",
      " [ 0  0  0  4  0  0]\n",
      " [ 0  1  0  2  0  0]\n",
      " [ 0  0  0  0  0  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.93      0.74        14\n",
      "           2       0.82      0.67      0.74        21\n",
      "           3       0.00      0.00      0.00         4\n",
      "           5       0.50      1.00      0.67         4\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.72        54\n",
      "   macro avg       0.49      0.60      0.52        54\n",
      "weighted avg       0.67      0.72      0.68        54\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kishan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "y_pred=dt.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, dt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=3,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=5,p=3) #type of distance, p=3, it is for minwoski distance\n",
    "#p=2=> Eucledean Distance\n",
    "#p=1=>Manhattan Distance\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6111111111111112\n",
      "[[12  1  1  0  0  0]\n",
      " [ 6 11  1  1  2  0]\n",
      " [ 4  0  0  0  0  0]\n",
      " [ 0  1  0  2  0  1]\n",
      " [ 0  1  0  0  1  1]\n",
      " [ 0  0  0  0  1  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.86      0.67        14\n",
      "           2       0.79      0.52      0.63        21\n",
      "           3       0.00      0.00      0.00         4\n",
      "           5       0.67      0.50      0.57         4\n",
      "           6       0.25      0.33      0.29         3\n",
      "           7       0.78      0.88      0.82         8\n",
      "\n",
      "    accuracy                           0.61        54\n",
      "   macro avg       0.50      0.51      0.50        54\n",
      "weighted avg       0.63      0.61      0.60        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "y_pred=knn.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, knn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion (it works on Multinomial Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kishan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kishan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg=LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5925925925925926\n",
      "[[12  2  0  0  0  0]\n",
      " [ 9 11  0  0  0  1]\n",
      " [ 3  1  0  0  0  0]\n",
      " [ 0  3  0  1  0  0]\n",
      " [ 0  1  0  0  0  2]\n",
      " [ 0  0  0  0  0  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.86      0.63        14\n",
      "           2       0.61      0.52      0.56        21\n",
      "           3       0.00      0.00      0.00         4\n",
      "           5       1.00      0.25      0.40         4\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.73      1.00      0.84         8\n",
      "\n",
      "    accuracy                           0.59        54\n",
      "   macro avg       0.47      0.44      0.41        54\n",
      "weighted avg       0.55      0.59      0.54        54\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kishan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "y_pred=log_reg.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, log_reg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: The maximum accuracy was from SVM with 'Ploy' kernel i.e, 76%. So we will use this to perform the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The more you can do is:\n",
    "    # Use other classification models\n",
    "    # Use hypertuning the models parameters\n",
    "    # Use feature selection or extractions \n",
    "    # Choose a larger dataset\n",
    "    # Use Ensemble techniques"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
